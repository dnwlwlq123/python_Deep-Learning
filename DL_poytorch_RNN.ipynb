{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def generate_dataset(seq_length, num_sample, vocab_size):\n",
    "  inputs = torch.randint(1, vocab_size, (num_sample, seq_length))\n",
    "  outputs = inputs.clone()\n",
    "  return TensorDataset(inputs, outputs)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.linear = nn.Linear(input_size, hidden_size)\n",
    "    self.activation = nn.Tanh()\n",
    "  \n",
    "  def forward(self, input_seq):\n",
    "    batch_size, seq_length = input_seq.size()\n",
    "    hidden = torch.zeros(batch_size, self.hidden_size).to(input_seq.device)\n",
    "\n",
    "    for char_idx in range(seq_length):\n",
    "      x_t = nn.functional.one_hot(input_seq[:, char_idx], num_classes = self.linear.in_features).float().to(input_seq.device)\n",
    "      hidden = self.activation(self.linear(x_t) + hidden)\n",
    "    return hidden\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self,input_size, hidden_size, output_size):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.input_size = input_size\n",
    "    self.output_size = output_size\n",
    "\n",
    "    #self.i2h = nnLinear(input_size, hidden_size) ####  RNN\n",
    "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "    self.activation = nn.Tanh()\n",
    "    self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "  def forward(self, target_seq, hidden):\n",
    "    batch_size, seq_len = target_seq.size()\n",
    "    outputs = torch.zeros(batch_size, seq_len, self.output_size).to(target_seq.device)\n",
    "\n",
    "    for char_idx in range(seq_len):\n",
    "      if char_idx == 0:\n",
    "        previous_y = torch.zeros(batch_size, self.input_size).to(target_seq.device)\n",
    "      else : \n",
    "        y_prev = target_seq[:, char_idx - 1]\n",
    "        previous_y = nn.functional.one_hot(y_prev, num_classes=self.input_size).float().to(target_seq.device)\n",
    "\n",
    "      hidden = self.activation(self.linear1(previous_y) + hidden)\n",
    "      output = self.linear2(hidden)\n",
    "      outputs[:, char_idx, :] = output\n",
    "    return outputs\n",
    "class Seq2Seq(nn.Module):\n",
    "  def __init__(self, encoder, decoder):\n",
    "    super(Seq2Seq, self).__init__()\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "\n",
    "  def forward(self, input_seq, target_seq):\n",
    "    encoder_hidden = self.encoder(input_seq)\n",
    "    decoder_hidden = self.decoder(target_seq, encoder_hidden)\n",
    "    return decoder_hidden\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs, device):\n",
    "  model.to(device)\n",
    "  for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for inputs, targets in dataloader:\n",
    "      # inputs.shage - batch_size, sequence_length\n",
    "      inputs, targets = inputs.to(device), targets.to(device)\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      outputs = model(inputs, targets)\n",
    "      outputs = outputs.view(-1, outputs.size(-1))\n",
    "      targets = targets.view(-1)\n",
    "\n",
    "      loss = criterion(outputs, targets)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      epoch_loss += loss.item()\n",
    "  \n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    print(f\"Epoch : {epoch}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "  model.eval()\n",
    "\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  with torch.no_grad():\n",
    "    for inputs, targets in dataloader:\n",
    "      inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "      outputs = model(inputs, targets)\n",
    "      predicted = torch.argmax(outputs, dim=2)\n",
    "      correct += (predicted == targets).sum().item()\n",
    "      total += targets.numel()\n",
    "    acc = correct / total\n",
    "    return acc\n",
    "\n",
    "\n",
    "seq_length = 10\n",
    "num_samples = 1000\n",
    "vocab_size = 5\n",
    "input_size = vocab_size\n",
    "hidden_size = 130\n",
    "output_size = vocab_size\n",
    "learning_rate = 0.001\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "dataset = generate_dataset(seq_length, num_samples, vocab_size)\n",
    "dataloader = DataLoader(dataset, batch_size = 64, shuffle=True)\n",
    "\n",
    "\n",
    "encoder = Encoder(input_size, hidden_size)\n",
    "decoder = Decoder(input_size, hidden_size, output_size)\n",
    "model = Seq2Seq(encoder, decoder).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate)\n",
    "\n",
    "\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs=155, device=device)\n",
    "\n",
    "acc = evaluate_model(model, dataloader, device)\n",
    "print(f\"Traning Accuracy: {acc*100:.2f}%\\n\")\n",
    "with torch.no_grad():\n",
    "  test_input, test_target = dataset[0]\n",
    "  test_input = test_input.unsqueeze(0).to(device)\n",
    "  test_target = test_target.unsqueeze(0).to(device)\n",
    "\n",
    "  output = model(test_input, test_target)\n",
    "\n",
    "  predicted = torch.argmax(output, dim = 2)\n",
    "  print(\"Sample Input Sequence : \", test_input.squeeze().tolist())\n",
    "  print(\"Sample Target Sequence:\", test_target.squeeze().tolist())\n",
    "  print(\"Predicted Sequence    : \", predicted.squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
